{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitc30deacdfc314bf0ab55258624adc68b",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "https://github.com/datacamp/course-resources-ml-with-experts-budgets\n",
    "## Topic: \n",
    "School Budgets problem from DrivenData.org\n",
    "School budgets are huge, complex and non-standardized within the US\n",
    "School want to measure their performance\n",
    "## Goal: \n",
    "Build Machine Learning Algorithm that automate the labeling of spendings\n",
    "## Data:\n",
    "Line-Data with description:\n",
    "like \"Algebra books for 8th grade students\"\n",
    "Labels attached like: \"Math\", \"Middle School\", \"Textbooks\"\n",
    "## Type of the problem:\n",
    "Supervised Learning Problem -> Using correct labeled data to predict the label of an unlabeled sample\n",
    "predict the label -> Classification problem\n",
    "predict the probability of each target variables possible value (logreg?)\n",
    "## Specials:\n",
    "Over 100 target variables\n",
    "9 columns with several possible Labels\n",
    "predicting variable-value-probabilities via dummy variables\n",
    "## Exploring the data:\n",
    "Loading dataset via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Unnamed: 0                 Function          Use          Sharing  \\\n0      134338     Teacher Compensation  Instruction  School Reported   \n1      206341                 NO_LABEL     NO_LABEL         NO_LABEL   \n2      326408     Teacher Compensation  Instruction  School Reported   \n3      364634  Substitute Compensation  Instruction  School Reported   \n4       47683  Substitute Compensation  Instruction  School Reported   \n\n  Reporting Student_Type Position_Type               Object_Type     Pre_K  \\\n0    School     NO_LABEL       Teacher                  NO_LABEL  NO_LABEL   \n1  NO_LABEL     NO_LABEL      NO_LABEL                  NO_LABEL  NO_LABEL   \n2    School  Unspecified       Teacher  Base Salary/Compensation  Non PreK   \n3    School  Unspecified    Substitute                  Benefits  NO_LABEL   \n4    School  Unspecified       Teacher   Substitute Compensation  NO_LABEL   \n\n    Operating_Status  ... Sub_Object_Description Location_Description  FTE  \\\n0  PreK-12 Operating  ...                    NaN                  NaN  1.0   \n1      Non-Operating  ...                    NaN                  NaN  NaN   \n2  PreK-12 Operating  ...                    NaN                  NaN  1.0   \n3  PreK-12 Operating  ...                    NaN                  NaN  NaN   \n4  PreK-12 Operating  ...                    NaN                  NaN  NaN   \n\n      Function_Description Facility_or_Department              Position_Extra  \\\n0                      NaN                    NaN               KINDERGARTEN    \n1                 RGN  GOB                    NaN                UNDESIGNATED   \n2                      NaN                    NaN                     TEACHER   \n3  UNALLOC BUDGETS/SCHOOLS                    NaN  PROFESSIONAL-INSTRUCTIONAL   \n4              NON-PROJECT                    NaN  PROFESSIONAL-INSTRUCTIONAL   \n\n       Total             Program_Description        Fund_Description  \\\n0  50471.810                    KINDERGARTEN            General Fund   \n1   3477.860   BUILDING IMPROVEMENT SERVICES                     NaN   \n2  62237.130           Instruction - Regular  General Purpose School   \n3     22.300  GENERAL MIDDLE/JUNIOR HIGH SCH                     NaN   \n4     54.166   GENERAL HIGH SCHOOL EDUCATION                     NaN   \n\n                          Text_1  \n0                            NaN  \n1  BUILDING IMPROVEMENT SERVICES  \n2                            NaN  \n3            REGULAR INSTRUCTION  \n4            REGULAR INSTRUCTION  \n\n[5 rows x 26 columns]\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 400277 entries, 0 to 400276\nData columns (total 26 columns):\nUnnamed: 0                400277 non-null int64\nFunction                  400277 non-null object\nUse                       400277 non-null object\nSharing                   400277 non-null object\nReporting                 400277 non-null object\nStudent_Type              400277 non-null object\nPosition_Type             400277 non-null object\nObject_Type               400277 non-null object\nPre_K                     400277 non-null object\nOperating_Status          400277 non-null object\nObject_Description        375493 non-null object\nText_2                    88217 non-null object\nSubFund_Description       306855 non-null object\nJob_Title_Description     292743 non-null object\nText_3                    109152 non-null object\nText_4                    53746 non-null object\nSub_Object_Description    91603 non-null object\nLocation_Description      162054 non-null object\nFTE                       126071 non-null float64\nFunction_Description      342195 non-null object\nFacility_or_Department    53886 non-null object\nPosition_Extra            264764 non-null object\nTotal                     395722 non-null float64\nProgram_Description       304660 non-null object\nFund_Description          202877 non-null object\nText_1                    292285 non-null object\ndtypes: float64(2), int64(1), object(23)\nmemory usage: 79.4+ MB\nNone\n          Unnamed: 0            FTE         Total\ncount  400277.000000  126071.000000  3.957220e+05\nmean   225186.018537       0.426794  1.310586e+04\nstd    130025.142718       0.573576  3.682254e+05\nmin         2.000000      -0.087551 -8.746631e+07\n25%    112601.000000       0.000792  7.379770e+01\n50%    225243.000000       0.130927  4.612300e+02\n75%    337722.000000       1.000000  3.652662e+03\nmax    450340.000000      46.800000  1.297000e+08\n<class 'pandas.core.series.Series'>\n<class 'pandas.core.frame.DataFrame'>\n"
    }
   ],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "\n",
    "#load a sample set of the data  !!!!!!!!!!!!! -- Change to the real dataset\n",
    "sample_df = pd.read_csv(\"TrainingData.csv\")\n",
    "\n",
    "#explore basics via head (data example), info(data structure) and describe(summary statistics)\n",
    "print(sample_df.head())\n",
    "print( sample_df.info())\n",
    "print(sample_df.describe())\n",
    "NUMERIC_COLUMNS = list(sample_df.loc[:,sample_df.dtypes != \"object\"].columns)\n",
    "LABELS = ['Function',\n",
    " 'Use',\n",
    " 'Sharing',\n",
    " 'Reporting',\n",
    " 'Student_Type',\n",
    " 'Position_Type',\n",
    " 'Object_Type',\n",
    " 'Pre_K',\n",
    " 'Operating_Status']\n",
    "df = sample_df\n",
    "\n",
    "print(type(df[\"FTE\"]))\n",
    "print(type(df[[\"FTE\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information obtained:\n",
    "* Strings in values in several columns\n",
    "* NaNs found in several columns \n",
    "\n",
    "### Encountered problems\n",
    "* ML works with numbers not with strings \n",
    "* Strings are computationally expensive\n",
    "    * Category - Datatype from pandas could solve the issue by storing this information numerically\n",
    "\n",
    "### What to do \n",
    "create lambda function to change each object type column into categorical column\n",
    "\n",
    "    categorize = lambda x = x.astype(\"category\")\n",
    "\n",
    "Apply this function to desired column using .apply()-method\n",
    "\n",
    "    sample_df.label = sample_df[[\"label\"]].apply(categorize, axis=0) ((use a list of column labels))\n",
    "\n",
    "Count the numbers of unique categorical values per Category via .apply(pd.Series.nunique)\n",
    "\n",
    "    num_unique_values = sample_df[[\"label\"]].apply(pd.Series.nunique)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure of model sucess\n",
    "### Logloss function\n",
    "The Logloss-function is used in this competition to evaluate the model performace\n",
    "\n",
    "see:  https://www.drivendata.org/competitions/46/box-plots-for-education-reboot/submissions/\n",
    "\n",
    "-> being less sure is better than confident and wrong\n",
    "\n",
    "Loglossfunction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6931471805599453"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "import numpy as np\n",
    "def compute_log_loss(predicted, actual, eps=1e-14):\n",
    "    predicted = np.clip(predicted, eps, 1-eps)\n",
    "    loss = -1 * np.mean(actual * np.log(predicted)\n",
    "                +(1-actual)\n",
    "                *np.log(1-predicted))\n",
    "    return loss\n",
    "compute_log_loss(0.5, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting with a simple model\n",
    "gives a sense of how complex and difficult the problem might be  \n",
    "wanting to come as fast as possible from raw data to prediction  \n",
    "Using Multi-class logistic regression  \n",
    "Format predictions and save to csv  \n",
    "Submit\n",
    "\n",
    "### Splitting the dataset\n",
    "Normal train-test-split does not work here, because of many different labels\n",
    "\n",
    "### Solution:  \n",
    "\n",
    "    StratifiedShuffleSplit\n",
    "* Con: Only works with single target variable\n",
    "* We have many target variables\n",
    "* multilabel_train_test_split()  \n",
    "  \n",
    "    Code here\n",
    "  \n",
    "### How to:\n",
    "\n",
    "Minimal preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Unnamed: 0', 'FTE', 'Total']\n['Function', 'Use', 'Sharing', 'Reporting', 'Student_Type', 'Position_Type', 'Object_Type', 'Pre_K', 'Operating_Status']\n"
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'multilabel_train_test_split' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c764758d4111>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata_to_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mNUMERIC_COLUMNS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlabels_to_use\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mLABELS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m X_train, X_test, y_train, y_test = multilabel_train_test_split(data_to_train, \n\u001b[0m\u001b[0;32m      7\u001b[0m                                                                \u001b[0mlabels_to_use\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                                                                \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'multilabel_train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "print(NUMERIC_COLUMNS)  #list of all numeric columns \n",
    "print(LABELS)#List of target label columns\n",
    "\n",
    "data_to_train = df[NUMERIC_COLUMNS].fillna(-1000)\n",
    "labels_to_use = pd.get_dummies(df[LABELS])\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(data_to_train, \n",
    "                                                               labels_to_use, \n",
    "                                                               size =0.2, \n",
    "                                                               seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.linar_model'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-349d12106d66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinar_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.linar_model'"
     ]
    }
   ],
   "source": [
    "from sklearn.linar_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "clf = OneVsRestClassifier(LogisticRegression()) \n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "    OneVsRestClassifier\n",
    "   \n",
    "treats each column of y independently  \n",
    "Fits a separate classifier for each of the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating competing in the Competition\n",
    "## Loading Test_set (Holdout data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0'] not in index\"",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-dfa87d315be1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mholdout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TestData.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mholdout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mholdout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mNUMERIC_COLUMNS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mholdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2999\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3000\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3001\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3002\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3003\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1283\u001b[0m                 \u001b[1;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"raise_missing\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1092\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m         )\n\u001b[0;32m   1094\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1183\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"loc\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} not in index\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m             \u001b[1;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Unnamed: 0'] not in index\""
     ]
    }
   ],
   "source": [
    "holdout = pd.read_csv(\"TestData.csv\", index_col=0)\n",
    "holdout = holdout[NUMERIC_COLUMNS].fillna(-1000)\n",
    "predictions = clf.predict_proba(holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the use of Logloss, .predict() would be much worse (only 0s and 1s)  \n",
    "-> Using **.predict_proba()** solves the problem giving probabilities rather than predictions  \n",
    "  \n",
    "  \n",
    "## Formatting and submission of predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = pd.DataFrame(columns = pd.get_dummies(df[LABELS], prefix_sep=\"__\").columns, index=holdout.index, data=predictions)\n",
    "prediction.df.to_csv(\"precitions.csv\")\n",
    "score = score_submission(pred_path=\"predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload and obtain score from the Leaderboard\n",
    "\n",
    "# Introduction to NLP\n",
    "Data: Text, documents, speech\n",
    "\n",
    "## First step: Tokenization  \n",
    "* Splitting a string into segments\n",
    "* Store results as lists  \n",
    "Example:  \n",
    "\"Natural Language Processing\"  \n",
    "  \n",
    "\"Natural\", \"Language\",\"Processing\"  \n",
    "\n",
    "Tokenize on:  \n",
    "* whitespace\n",
    "* punctuation\n",
    "\n",
    "## Using \"bag of words\"\n",
    "* Count the number of times a particular token appears\n",
    "* Bag of words:  \n",
    "  * Count the number of times a word was pulled out of the bag  \n",
    "* This approach discards the information about word order\n",
    "->\"Red, not blue\" == \"blue, not red\"  \n",
    "  \n",
    "## Using n-gram\n",
    "1-gram, 2-gram,...,n-gram\n",
    "\n",
    "Not a single word is treated as an occurance to count but every ordered 2 word pair = \"2-gram\"\n",
    "  \n",
    "## Representing words numerically\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Bag-of-Word representation\n",
    "Using: sklearns CountVectorizor\n",
    "\n",
    "does 3 things:\n",
    "    Tokenize all strings\n",
    "    Builds a vocabulary\n",
    "    Counts the tokens apprearance\n",
    "How?'''\n",
    "\n",
    "#import packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#define regular_expression that does the split on whitespaces\n",
    "TOKEN_BASIC = \"\\\\\\\\S+(=\\\\\\\\s+)\"\n",
    "\n",
    "#replace NaNs with empty strings\n",
    "df.Program_Description.fillna(\"\", inplace = True)\n",
    "\n",
    "#instantiate CountVectorizer\n",
    "vec_basic = CountVectorizer(token_pattern=TOKEN_BASIC)\n",
    "\n",
    "#fit the vectorizer\n",
    "vec_basic.fit(df.Program_description)\n",
    "\n",
    "#Extract found words by using get_feature_names()-method on vectorizer\n",
    "features = vec_basic.get_feature_names()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline, features & test processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "= Repeatable way to go from raw data to trained model ->see unsupervised-learning notes\n",
    "  \n",
    "Pipelines can also have sub-pipelines as steps\n",
    "  \n",
    "## How to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-285340985b7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#split data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"numeric\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#import packages:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "#initiate pipeline\n",
    "pl = Pipeline([(\"clf\", OneVsRestClassifier(LogisticRegression()))])\n",
    "\n",
    "#split data !![[for getting a dataframe instead of a Series]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[[\"numeric\"]], pd.get_dummies(df[\"label\"]), random_state = 2)\n",
    "\n",
    "#fit\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "#score on test\n",
    "pl.score(X_test, y_test)\n",
    "\n",
    "#Throwing with NaNs will cause a break_down\n",
    "#Therefore: create Imputer (convert NaNs)\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "pl = Pipeline([(\"imp\", Imputer),\n",
    "               (\"clf\", OneVsRestClassifier(LogisticRegression())\n",
    "                )])\n",
    "\n",
    "#fit and score with nans\n",
    "\n",
    "\n",
    "## Implementing text features into the pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"], pd.get_dummies(df[\"label\"]), random_state=2)\n",
    "\n",
    "pl = Pipeline([(\"vec\" , CountVectorizer()),\n",
    "                (\"clf\" , OneVsRestClassifier(LogisticRegression())])\n",
    "\n",
    "#fit and score again\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing multiple dtypes\n",
    "* Using all variables from different types\n",
    "* Problem:\n",
    "    * Pipelines cannot follow each other \n",
    "    * e.g., CountVec can't be input for Imputer\n",
    "* Solution: FunctionTransformer() & FeatureUnion()  \n",
    "  \n",
    "\n",
    "### Functiontransformer()\n",
    "* Turn Python function into object, understandable by scikit-learn Pipelines  \n",
    "* Need to write two functions for pipeline preprocessing  \n",
    "    1 Takes hole dataframe, returns numeric columns  \n",
    "2 Takes hole dataframe, returns text columns\n",
    "\n",
    "## How to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "#split complete set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[[\"numeric\", \"with_missing\", \"text\"]], pd.get_dummies(df[\"label\"]), random_state = 1)\n",
    "\n",
    "get_text_data = FunctionTransformer(lambda x: x[\"text\"], validate = False)\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[[\"numeric\", \"with_missing\"]], validate = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FeatureUnion\n",
    "combines the two outcomes into one dataframe\n",
    "\n",
    "## HowTo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union = FeatureUnion([(\"numeric\", numeric_pipeline),\n",
    "                     (\"text\", text_pipeline)])                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "#split complete set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[[\"numeric\", \"with_missing\", \"text\"]], pd.get_dummies(df[\"label\"]), random_state = 1)\n",
    "\n",
    "get_text_data = FunctionTransformer(lambda x: x[\"text\"], validate = False)\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[[\"numeric\", \"with_missing\"]], validate = False)\n",
    "#to obtain results use fit_transform(x)\n",
    "\n",
    "\n",
    "#create numeric sub-pipeline\n",
    "numeric_pipeline = Pipeline([\n",
    "                            (\"selector\", get_numeric_data),\n",
    "                            (\"imputer\", Imputer())\n",
    "                            ])\n",
    "\n",
    "#create text sub-pipeline\n",
    "text_pipeline = Pipeline([\n",
    "                        (\"selector\", get_text_data),\n",
    "                        (\"vectorizer\"), CountVectorizer())\n",
    "                        ])\n",
    "#create final pipeline with featureunion and two subs + model\n",
    "pl = Pipeline([\n",
    "                (\"union\", FeatureUnion([\n",
    "                                        (\"numeric\", numeric_pipeline)\n",
    "                                        (\"text\", text_pipeline)\n",
    "                                        ])),\n",
    "                (\"clf\" , OneVsRestClassifier(LogisticRegression()))\n",
    "                ])\n",
    "\n",
    "#fit the data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "#get the score\n",
    "pl.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the pipeline with the main dataset\n",
    "\n",
    "#import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"TrainingData.csv\", index_col=0)"
   ]
  }
 ]
}